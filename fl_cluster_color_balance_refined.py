# -*- coding: utf-8 -*-
"""FL_Cluster_color_balance_refined-yx2.ipynb（副本）

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TnhGfTMhyy5CwbS5mwELlo_dpfJEoS8M
"""

import numpy as np
import pandas as pd
# import geovoronoi

import statistics
 
import matplotlib.pyplot as plt
import seaborn as sns
import geopandas as gpd

from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn import metrics, linear_model
import geopy.distance

"""# Load and explore"""

# data = pd.read_csv('archive/flights.csv', nrows=50000) # subset
data = pd.read_csv('flight_data/flights.csv',low_memory=False) # all data

data

# data.info()

"""# Data Prep for Clustering"""

#Re-pre-processing
df_pp = data


# df_pp['DELAY'] = [1 if x > 15 else 0 for x in df_pp['DEPARTURE_DELAY']]
df_pp['DELAY'] = [1 if x > 0 else 0 for x in df_pp['DEPARTURE_DELAY']]

# Remove columns with more than 25% missing values
missing_columns = df_pp.loc[:, df_pp.isna().mean() >= 0.25].columns
df_pp = df_pp.drop(missing_columns, axis=1)


# We will not consider cancelled or diverted flights as cancellation, diversion and delay should be exclusive
df_pp = df_pp[df_pp.CANCELLED != 1]
df_pp = df_pp[df_pp.DIVERTED != 1]

# Drop all columns that do not add interpretability to the model
df_pp = df_pp.drop(['FLIGHT_NUMBER', 'TAIL_NUMBER','TAXI_OUT','SCHEDULED_DEPARTURE','WHEELS_OFF',
                  'WHEELS_ON','TAXI_IN','SCHEDULED_ARRIVAL','DIVERTED','CANCELLED','ARRIVAL_DELAY','DEPARTURE_DELAY'], axis=1)
    
# Fill NaNs
df_pp = df_pp.fillna(0)
FL_Airports = ['PNS','VPS','ECP','TLH','JAX','GNV','DAB','SFB','MCO','TPA','PIE','MLB','VRB','SRQ','PGD','RSW','PBI','FXE','FLL','MIA','EYW']
indices=[9, 24, 40, 8, 4, 17, 10, 13, 0, 3, 11, 22, 23, 12, 30, 6, 5, 14, 2, 1, 7] #based on 'us-fl-airports.csv'
df_pp

# funtion to extract flight data within a time window
def time_window(data,month,day,wstart,wend):
  Month = data.loc[data['MONTH'] == month]
  Day = Month.loc[Month['DAY'] == day]
  Day = Day.sort_values(by=['ARRIVAL_TIME'])
  window_data =  Day.loc[(Day['ARRIVAL_TIME'] >= wstart) & (Day['ARRIVAL_TIME'] < wend)]

  #extract FL flights and delay flights
  FL_flights = pd.DataFrame()
  print(FL_flights)
  Airport_Flights = []
  Airport_DelayFlights = []
  for airport in FL_Airports:
    df = window_data[(window_data.DESTINATION_AIRPORT == airport) | (window_data.ORIGIN_AIRPORT == airport)]
    # FL_flights = FL_flights.append(df)
    FL_flights = pd.concat([FL_flights, df])
    Airport_Flights.append(df.shape[0])
    Airport_DelayFlights.append(df[df.DELAY==1].shape[0])

  # print('Number of flights in FL: ', FL_flights.shape[0])
  # print('Number of delayed flights in FL: ', FL_flights[FL_flights.DELAY == 1].shape[0])
  # print('Numer of airports in FL:', len(Airport_Flights))

  d = {'FL_Airports': FL_Airports, 'indices': indices,'Airport_Flights': Airport_Flights, 'Airport_DelayFlights': Airport_DelayFlights}
  FLAirport_detail = pd.DataFrame(data=d)
  return FLAirport_detail

FL_ATC_Count = {}

FL_ATC_Count['MCO']=22
FL_ATC_Count['DAB']=47
FL_ATC_Count['PNS']=7
FL_ATC_Count['TLH']=14
FL_ATC_Count['JAX']=38
FL_ATC_Count['SFB']=17
FL_ATC_Count['MCO']=22
FL_ATC_Count['TPA']=47
FL_ATC_Count['PIE']=10
FL_ATC_Count['VRB']=10
FL_ATC_Count['SRQ']=13
FL_ATC_Count['RSW']=29
FL_ATC_Count['PBI']=46
FL_ATC_Count['FXE']=14
FL_ATC_Count['FLL']=25
FL_ATC_Count['MIA']=59

"""# Visualization

## FL Map
"""

# Read the shapefile
gdf = gpd.read_file("USA_Counties/USA_Counties_(Generalized).shp")
# gdf_fl = gpd.read_file("USA_Counties/Detailed_Florida_State_Boundary.geojson")
# Print the first few rows of the GeoDataFrame
# print(gdf.head())

# gdf.plot();

# Filter to keep only florida counties
list_of_names = ['Florida']
FL_county = gdf.query('STATE_NAME in @list_of_names')

"""## Airports"""

FL_Airports = ['PNS','VPS','ECP','TLH','JAX','GNV','DAB','SFB','MCO','TPA','PIE','MLB','VRB','SRQ','PGD','RSW','PBI','FXE','FLL','MIA','EYW']
indices=[9, 24, 40, 8, 4, 17, 10, 13, 0, 3, 11, 22, 23, 12, 30, 6, 5, 14, 2, 1, 7] #based on 'us-fl-airports.csv'

# Airports Map
df_loc = pd.read_csv('us-fl-airports.csv')
FL_air_loc = pd.DataFrame()

for airport in FL_Airports:
    df = df_loc[df_loc.local_code == airport]
    # FL_air_loc = FL_air_loc.append(df)
    FL_air_loc =pd.concat([FL_air_loc, df])

FL_air_loc = FL_air_loc[['name','type','local_code','latitude_deg','longitude_deg']]
FL_air_loc

locDetails = FL_air_loc
lat = locDetails[locDetails['local_code']== 'DAB']['latitude_deg']
lon = locDetails[locDetails['local_code']== 'DAB']['longitude_deg']
coord1 = (lat.values[0],lon.values[0])
lat = locDetails[locDetails['local_code']== 'MCO']['latitude_deg']
lon = locDetails[locDetails['local_code']== 'MCO']['longitude_deg']
coord2 = (lat.values[0],lon.values[0])

# import geopy.distance
print(geopy.distance.geodesic(coord1, coord2).km)

import matplotlib.pyplot as plt
fig, ax=plt.subplots(figsize=(8,8))

# plt.plot(FL_air_loc.latitude_deg,FL_air_loc.longitude_deg,'o')
FL_county.plot(ax=ax,edgecolor='white',linewidth=1,facecolor="skyblue",alpha=0.8)
ax.plot(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg,'r*')
# plt.savefig('airport_loc.png')

# _, ax = plt.subplots()
# ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg)
# # ax.plot(FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg)
# for i, txt in enumerate(FL_air_loc):
#     indices = FL_air_loc.index[FL_air_loc['local_code']  == FL_Airports[i]]
#     # indices = FL_air_loc.index[FL_air_loc['FL_Airports']  == FL_Airports[i]]
#     ax.annotate(indices[0], (FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg))
# plt.savefig('airport_inx.png')

# _, ax = plt.subplots()
# print(type(FL_air_loc.longitude_deg))
ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg)    
# from geovoronoi import voronoi_regions_from_coords
# print(FL_air_loc.longitude_deg.to_numpy())
# lon = FL_air_loc.longitude_deg.to_numpy()
# lat = FL_air_loc.latitude_deg.to_numpy()
# coords = np.vstack((lon,lat)).T
# print(coords)
# region_polys, region_pts = voronoi_regions_from_coords([coords], FL_county)


for i, txt in enumerate(FL_Airports):
    ax.annotate(txt, (FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg))
# # plt.savefig('airport_name.png')

"""# Spectral Clustering

## Create Adjacent Matrix

Assume the conection are like below, which is based on the distance to distribute the flights during emergency:
"""

# Add a vertex to the set of vertices and the graph
def add_vertex(v):
  global graph
  global vertices_no
  global vertices
  if v in vertices:
    print("Vertex ", v, " already exists")
  else:
    vertices_no = vertices_no + 1
    vertices.append(v)
    if vertices_no > 1:
        for vertex in graph:
            vertex.append(0)
    temp = []
    for i in range(vertices_no):
        temp.append(0)
    graph.append(temp)

# Add an edge between vertex v1 and v2 with edge weight e
def add_edge(v1, v2, Airport_delay, distWeight=0):
  global graph
  global vertices_no
  global vertices
      
  # Check if vertex v1 is a valid vertex
  if v1 not in vertices:
    print("Vertex ", v1, " does not exist.")
  # Check if vertex v1 is a valid vertex
  elif v2 not in vertices:
    print("Vertex ", v2, " does not exist.")
  # Since this code is not restricted to a directed or 
  # an undirected graph, an edge between v1 v2 does not
  # imply that an edge exists between v2 and v1
  else:
    locDetails = FL_air_loc
    lat = locDetails[locDetails['local_code'] == v1]['latitude_deg']
    lon = locDetails[locDetails['local_code'] == v1]['longitude_deg']
    coord1 = (lat.values[0],lon.values[0])
    lat = locDetails[locDetails['local_code'] == v2]['latitude_deg']
    lon = locDetails[locDetails['local_code'] == v2]['longitude_deg']
    coord2 = (lat.values[0],lon.values[0])

    d = geopy.distance.geodesic(coord1, coord2).km
    e = weight_transform(Airport_delay,v1,v2,d,distWeight)
    index1 = vertices.index(v1)
    index2 = vertices.index(v2)
    graph[index1][index2] = e
    graph[index2][index1] = e

# Print the graph
def print_graph():
  global graph
  global vertices_no
  for i in range(vertices_no):
    for j in range(vertices_no):
      if graph[i][j] != 0:
        print(vertices[i], " -> ", vertices[j], " edge weight: ", graph[i][j])
        
# encode workload into edge weight (large delay/all ratio->less connection)
def weight_transform(Airport_delay,dp,ar, dist=-1, distWeight = 0):
  base = 0.99
  delay = get_delay(Airport_delay,dp) + get_delay(Airport_delay,ar)
  all_flights = get_flights(Airport_delay, dp) + get_flights(Airport_delay, ar)
  if all_flights == 0:
    workload = 1 
  else:
    exponent = delay / all_flights
    # workload = round(base ** (exponent*100-300))
    # workload = round(base ** (exponent*100-300))*(1-distWeight) + (1/np.log(dist))*distWeight
    # workload = round(base ** ((1-distWeight)*(exponent*100-300)+distWeight*dist))
    workload = round(base ** (((1-distWeight)*(exponent*100)+distWeight*dist)-300))
  return workload

def get_flights(Airport_delay, airport):
  flights = Airport_delay[Airport_delay['FL_Airports'] == airport]['Airport_Flights']
  return flights.item()

def get_delay(Airport_delay, airport):
  delay = Airport_delay[Airport_delay['FL_Airports'] == airport]['Airport_DelayFlights']
  return delay.item()

# Construct adjancecy matrix
def completeAdjancecyMatrixOnDelay(Airport_delay, distWeight = 0):        
  # Add edge weight to the graph (airport order and connection are prefixed)
  add_edge('PNS','VPS', Airport_delay, distWeight)
  add_edge('VPS','ECP', Airport_delay, distWeight)
  add_edge('ECP','TLH', Airport_delay, distWeight)
  add_edge('TLH','JAX', Airport_delay, distWeight)
  add_edge('TLH','GNV', Airport_delay, distWeight)
  add_edge('JAX','GNV', Airport_delay, distWeight)
  add_edge('GNV','DAB', Airport_delay, distWeight)
  add_edge('GNV','SFB', Airport_delay, distWeight)
  add_edge('GNV','MCO', Airport_delay, distWeight)
  add_edge('GNV','TPA', Airport_delay, distWeight)
  add_edge('DAB','SFB', Airport_delay, distWeight)
  add_edge('SFB','MCO', Airport_delay, distWeight)
  add_edge('TPA','PIE', Airport_delay, distWeight)
  add_edge('MCO','MLB', Airport_delay, distWeight)
  add_edge('MCO','SRQ', Airport_delay, distWeight)
  add_edge('SRQ','MLB', Airport_delay, distWeight)
  add_edge('SRQ','PGD', Airport_delay, distWeight)
  add_edge('MLB','VRB', Airport_delay, distWeight)
  add_edge('VRB','PGD', Airport_delay, distWeight)
  add_edge('VRB','PBI', Airport_delay, distWeight)
  add_edge('PGD','RSW', Airport_delay, distWeight)
  add_edge('RSW','PBI', Airport_delay, distWeight)
  add_edge('RSW','FXE', Airport_delay, distWeight)
  add_edge('RSW','FLL', Airport_delay, distWeight)
  add_edge('RSW','MIA', Airport_delay, distWeight)
  add_edge('RSW','EYW', Airport_delay, distWeight)
  add_edge('EYW','MIA', Airport_delay, distWeight)
  # print_graph()

"""## The spatial clustering algorithm"""

def Spectral_Clustering(window_data, n_mean=5, distWeight = 0):
  # stores the vertices in the graph
  global vertices 
  # stores the number of vertices in the graph
  global vertices_no
  global graph 

  FLAirport_detail = window_data
  # Add vertices to the graph in the order of FL_Airports list
  for i in range(0,len(FLAirport_detail)):
      add_vertex(FLAirport_detail.iloc[i]['FL_Airports'])

  # Airport_delay = FLAirport_detail
  completeAdjancecyMatrixOnDelay(FLAirport_detail, distWeight)
  # print_graph()
  # print("Internal representation: ", graph)
  # graph

  # t0 = datetime.now()
  # Degree Matrix
  D = np.diag(np.array(graph).sum(axis=1))

  # Graph Laplacian
  L = D-graph
  # print(L)

  # eigenvalues and eigenvectors
  vals, vecs = np.linalg.eig(L)
  vals = vals.real
  vecs = vecs.real

  # sort these based on the eigenvalues
  vecs = vecs[:,np.argsort(vals)]
  vals = vals[np.argsort(vals)]
  # dt = datetime.now() - t0

  # kmeans on first n_mean vectors with nonzero eigenvalues
  # n_mean = 5
  kmeans = KMeans(n_clusters=n_mean,n_init='auto')
  kmeans.fit(vecs[:,1:n_mean])
  clusters = kmeans.labels_;

  # print("Pred time:", dt)
  return clusters

"""# Visualize Clutering result"""

# %pip install distinctipy
# from distinctipy import distinctipy
# N = 36
# # generate N visually distinct colours
# colors = distinctipy.get_colors(N)
# # display the colours
# distinctipy.color_swatch(colors)
# print(colors)

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors
# https://stackoverflow.com/questions/43938425/matplotlib-change-colormap-tab20-to-have-three-colors
# https://stackoverflow.com/questions/47222585/matplotlib-generic-colormap-from-tab10

# import matplotlib.pyplot as plt
# import numpy as np
# colors =  plt.cm.Vega20c( (4./3*np.arange(20*3/4)).astype(int) )
# plt.scatter(np.arange(15),np.ones(15), c=colors, s=180)
# plt.show()

# tab10 tab20 tab20b tab20c
def categorical_cmap(nc, nsc, cmap="tab10", continuous=False):
    if nc > plt.get_cmap(cmap).N:
        raise ValueError("Too many categories for colormap.")
    if continuous:
        ccolors = plt.get_cmap(cmap)(np.linspace(0,1,nc))
    else:
        ccolors = plt.get_cmap(cmap)(np.arange(nc, dtype=int))
    cols = np.zeros((nc*nsc, 3))
    for i, c in enumerate(ccolors):
        chsv = matplotlib.colors.rgb_to_hsv(c[:3])
        arhsv = np.tile(chsv,nsc).reshape(nsc,3)
        arhsv[:,1] = np.linspace(chsv[1],0.25,nsc)
        arhsv[:,2] = np.linspace(chsv[2],1,nsc)
        rgb = matplotlib.colors.hsv_to_rgb(arhsv)
        cols[i*nsc:(i+1)*nsc,:] = rgb       
    cmap = matplotlib.colors.ListedColormap(cols)
    return cmap

# c1 = categorical_cmap(4, 3, cmap="tab10")
# plt.scatter(np.arange(4*3),np.ones(4*3)+1, c=np.arange(4*3), s=180, cmap=c1)

# c2 = categorical_cmap(2, 5, cmap="tab10")
# plt.scatter(np.arange(10),np.ones(10), c=np.arange(10), s=180, cmap=c2)

colorBands = 20
intervalInBand = 1
c3 = categorical_cmap(colorBands, intervalInBand, cmap="tab20")
plt.scatter(np.arange(colorBands),np.ones(colorBands)-1, c=np.arange(colorBands), s=180, cmap=c3)    

plt.margins(y=0.3)
plt.xticks([])
# plt.yticks([0,1,2],[F"({colorBands}, {intervalInBand})", "(2, 5)", "(8, 2)"])
plt.yticks([0],[F"({colorBands}, {intervalInBand})"])
plt.show()

clusterColors = c3.colors

def visualize_result(Airport_delay, clusters, showMap=True, delayRatios = []):
  d = {'name': FL_air_loc['name'],'type': FL_air_loc['type'],'local_code': FL_air_loc['local_code']}
  cluster_result = pd.DataFrame(data=d)
  
  # cluster_result = FL_air_loc[['name','type','local_code']]
  # cluster_result = FL_air_loc
  # print(cluster_result)
  # print("*-*-*-*-*-*-bf.merge*-*-*-*-*-*-*-*-*-*-*-*-*-*-")     
  cluster_result = cluster_result.merge(Airport_delay[['FL_Airports','Airport_Flights','Airport_DelayFlights']], how='left', left_on=['local_code'], right_on = ['FL_Airports'])
  # cluster_result = cluster_result.merge(Airport_delay[['Airport_Flights','Airport_DelayFlights']], how='left', left_on=['local_code'], right_on = ['FL_Airports'])
  cluster_result['Delay%'] = (Airport_delay['Airport_DelayFlights']/Airport_delay['Airport_Flights'])
  cluster_result['Delay%']=round(cluster_result['Delay%'].fillna(0), 2)
  # print(cluster_result)
  # print("*-*-*-*-*-*-*-*-aft.merge*-*-*-*-*-*-*-*-*-*-*-*-")     
  # print(Airport_delay)
  # print("*-*-*-*-*-*-*-*-airport_delay*-*-*-*-*-*-*-*-*-*-*-*-")
  cluster_result['cluster'] = clusters.tolist()
  clusterNames = list(set(clusters.tolist()))


  # #plot
  # _, ax = plt.subplots()
  # ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg)

  # for i, txt in enumerate(cluster_result['cluster']):
  #     ax.annotate(txt, (FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg))
  #     plt.plot(FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg,c=txt)
      
  # plt.savefig('clusters.png')
  if showMap:
    fig, ax=plt.subplots(figsize=(8,8))
    FL_county.plot(ax=ax,edgecolor='white',linewidth=2,facecolor="plum",alpha=0.3)
    ## plot clusters different color
    # Define the colors for 8 classes
    colors = ['#ff0000', 'pink', '#ffa500', 'wheat','#ffff00', 'khaki','#008000', 'lightgreen', '#0000ff', 'lightskyblue','#4b0082', '#ee82ee', '#000000', 'darkgrey','gainsboro']
    # Create a scatter plot and set the color of each point based on its cluster
    # ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg, c=[colors[c] for c in clusters])
    ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg, c=[clusterColors[c] for c in clusters])
    # Add a legend with the label and color for each class
    if delayRatios != []:
      # legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {clusterNames[i]}, Delay%: {delayRatios[i]:.2f}', markerfacecolor=colors[i], markersize=10) for i in range(len(clusterNames))]
      legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {clusterNames[i]}, Delay: {delayRatios[i]*100:.2f}%', markerfacecolor=clusterColors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]
    else:
      # legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i}', markerfacecolor=colors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]
      legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i}', markerfacecolor=clusterColors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]

    # ax.legend(handles=legend_elements, loc='best')
    ax.legend(handles=legend_elements, loc='lower left')
    ax.set_xlabel('Longitude')
    ax.set_ylabel('Latitude')
    for i, txt in enumerate(FL_Airports):
        ax.annotate(txt, (FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg))
    # ax.show()
  return cluster_result

def visualize_result_without_recalculate(cluster_result,  delayRatios = []):
  clusters = cluster_result['cluster'].tolist()
  clusterNames = list(set(clusters))
  fig, ax=plt.subplots(figsize=(8,8))
  FL_county.plot(ax=ax,edgecolor='white',linewidth=2,facecolor="plum",alpha=0.3)
  ## plot clusters different color
  # Define the colors for 8 classes
  colors = ['#ff0000', 'pink', '#ffa500', 'wheat','#ffff00', 'khaki','#008000', 'lightgreen', '#0000ff', 'lightskyblue','#4b0082', '#ee82ee', '#000000', 'darkgrey','gainsboro']
  # Create a scatter plot and set the color of each point based on its cluster
  # ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg, c=[colors[c] for c in clusters])
  ax.scatter(FL_air_loc.longitude_deg,FL_air_loc.latitude_deg, c=[clusterColors[c] for c in clusters])

  # Add a legend with the label and color for each class
  if delayRatios != []:
    # legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {clusterNames[i]}, Delay%: {delayRatios[i]:.2f}', markerfacecolor=colors[i], markersize=10) for i in range(len(clusterNames))]
    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {clusterNames[i]}, Delay: {delayRatios[i]*100:.2f}%', markerfacecolor=clusterColors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]
  else:
    # legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i}', markerfacecolor=colors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]
    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=f'Cluster {i}', markerfacecolor=clusterColors[clusterNames[i]], markersize=10) for i in range(len(clusterNames))]

  # ax.legend(handles=legend_elements, loc='best')
  ax.legend(handles=legend_elements, loc='lower left')
  ax.set_xlabel('Longitude')
  ax.set_ylabel('Latitude')
  for i, txt in enumerate(FL_Airports):
      ax.annotate(txt, (FL_air_loc.iloc[i,:].longitude_deg,FL_air_loc.iloc[i,:].latitude_deg))
  # ax.show()

"""# Clustering & Banlance level evaluation"""

# sum delayed percentage of airports in the same cluster
def cluster_delay(cluster_number, cluster_list, AircraftPerSite= False):
  cluster_delay = []
  avgAircraftHandledPerAirport = []
  avgDelayedAircraftHandledPerAirport = []
  clusterLst = np.unique(cluster_list['cluster'].values)
  # for i in range(cluster_number):
  # clusterDelays = []
  for i in clusterLst:
    airports = cluster_list[cluster_list['cluster'] == i]['local_code'].values
    # sumATC = 0
    # for ap in airports:
    #   sumATC += FL_ATC_Count.get(ap, 0)
    
    totalFlights = cluster_list[cluster_list['cluster'] == i]['Airport_Flights'].sum(axis=0)
    delayedFlights = cluster_list[cluster_list['cluster'] == i]['Airport_DelayFlights'].sum(axis=0)
    clusterAvgDelayRate = cluster_list[cluster_list['cluster'] == i]['Delay%'].mean(axis=0)
    cluster_delay.append(clusterAvgDelayRate)
    avgAircraftHandledPerAirport.append(totalFlights/len(airports))
    avgDelayedAircraftHandledPerAirport.append(delayedFlights/len(airports))
    # print((totalFlights, delayedFlights))
    # if totalFlights != 0:
    #   cluster_delay.append(delayedFlights/totalFlights)
    # else:
    #   cluster_delay.append(0)
  if AircraftPerSite == True:
    return avgAircraftHandledPerAirport, avgDelayedAircraftHandledPerAirport
  else:
    return cluster_delay

"""# Experiments

## 7:00 to 9:00AM
"""

#Dec_24_12_15
startTime = 700
endTime = 900
Airport_delay = time_window(df_pp,12,24,startTime,endTime) 
 
# stores the vertices in the graph
vertices = []
# stores the number of vertices in the graph
vertices_no = 0
graph = []

n_mean = 8
cluster_result = Spectral_Clustering(Airport_delay,n_mean)
cluster_list = visualize_result(Airport_delay, cluster_result, False, [])
# Evaluatation
c_delay = cluster_delay(n_mean, cluster_list)
balance_level = statistics.variance(c_delay)
cluster_list = visualize_result(Airport_delay, cluster_result, False, c_delay)

timeStr = '12/24 7-9 AM'
print(timeStr)
print('Clusters: ', cluster_result)
print('Delay percentage of each cluster:', c_delay)
print('Unbalnace level of delay:', balance_level)
arPerSite = cluster_delay(n_mean, cluster_list, True)
print(F"Avg. aircraft handled per airport in cluster: {arPerSite[0]}")
print(F"Workload unbalance level: {statistics.variance(arPerSite[0])}")
# startClusterID = np.max(cluster_result) + 1
MAX_AIRPORT_PER_CLUSTER = 3
distWeight = 0.1
while True:
  clusterCount = np.unique(cluster_result, return_counts=True)
  stopFlag = True
  for i in range(len(clusterCount[0])):
    c_name = (clusterCount[0])[i]
    c_count = (clusterCount[1])[i]
    if c_count > MAX_AIRPORT_PER_CLUSTER:
      print(F"{c_name} needs re-adjust.")
      n_mean += 1
      distWeight = min(distWeight+0.1,0.5)
      if n_mean > 13:
        stopFlag = True;
        break
      # # dataframe[dataframe['Percentage'] > 80]
      # df = cluster_list[cluster_list['cluster'] == c_name]
      # nClusters = np.ceil(c_count / MAX_AIRPORT_PER_CLUSTER)
      # print(F"cluster {c_name} needs re-configure")
      # source = Airport_delay.loc[Airport_delay['FL_Airports'].isin(df['local_code'].tolist())]
      # print(source)
      # vertices = []
      # vertices_no = 0
      # graph = []
      # clusterAssignments = Spectral_Clustering(source, int(nClusters))
      # print(F"cluster {c_name} after re-configure")
      # print(clusterAssignments)
      # # print(visualize_result(source, clusterAssignments,False))
      stopFlag = False
      break
  if stopFlag == True:
    break
  vertices = []
  vertices_no = 0
  graph = []
  cluster_result = Spectral_Clustering(Airport_delay,n_mean, distWeight)
  print(F"New cluster result: {cluster_result}")
  cluster_list = visualize_result(Airport_delay, cluster_result, False)
  # Evaluatation
  c_delay = cluster_delay(n_mean, cluster_list)
  balance_level = statistics.variance(c_delay)
  print(timeStr)
  print('Clusters: ', cluster_result)
  print('Delay percentage of each cluster:', c_delay)
  print('Unbalnace level of the delay:', balance_level)
  arPerSite = cluster_delay(n_mean, cluster_list, True)
  print(F"Avg. aircraft handled per airport in cluster: {arPerSite[0]}")
  print(F"Workload unbalance level: {statistics.variance(arPerSite[0])}")
  print(F"Distance Weight: {distWeight}")
  # # print(type(cluster_result))

print(F"Before remerging")
cluster_list = visualize_result(Airport_delay, cluster_result, False, [])
c_delay = cluster_delay(n_mean, cluster_list)
balance_level = statistics.variance(c_delay)
visualize_result(Airport_delay, cluster_result, True, c_delay)
# cluster_list

from numpy.core.multiarray import busdaycalendar
from datetime import datetime

generateNewClusterAfterMerging = True
useCentroidToPreventOverlap = False

clusterNameLst = np.unique(cluster_list['cluster'].values)
maxClusterId = np.max(clusterNameLst)

duration = datetime.strptime(str(endTime),'%H%M') - datetime.strptime(str(startTime), "%H%M")
dhrs = duration.seconds/3600

busyCLusters = cluster_list[cluster_list['Airport_DelayFlights'] >= dhrs]['cluster'].values
busyAirports = cluster_list[cluster_list['Airport_DelayFlights'] >= dhrs][['local_code','cluster', 'Airport_Flights','Delay%','Airport_DelayFlights']]
busyAirports = busyAirports.sort_values(['Airport_DelayFlights','Delay%','Airport_Flights'],ascending=False)
# print(busyAirports)
busyAirports = busyAirports.values
# print(cluster_list)
nonBusyAirportLookupTbl = cluster_list[cluster_list['Airport_DelayFlights'] < dhrs][['local_code', 'cluster', 'Delay%', 'Airport_Flights', 'Airport_DelayFlights']]
# print(nonBusyAirportLookupTbl)
adjustList = []
afterMergeAirport = []
for item in busyAirports:
  # print(item)
  i_airport = item[0]
  i_cluster = item[1]
  i_delayRatio = item[2]
  i_delayFlights = item[3]
  nonBusyAirportInCluster = nonBusyAirportLookupTbl[nonBusyAirportLookupTbl['cluster']==i_cluster].sort_values(['Delay%','Airport_DelayFlights'])
  nonBusyAirportOutOfCluster = nonBusyAirportLookupTbl[nonBusyAirportLookupTbl['cluster']!=i_cluster].sort_values(['Delay%','Airport_DelayFlights'])

  lat = FL_air_loc[FL_air_loc['local_code'] == i_airport]['latitude_deg']
  lon = FL_air_loc[FL_air_loc['local_code'] == i_airport]['longitude_deg']
  coord1 = (lat.values[0],lon.values[0])
  
  ref_dist = []
  for i in range(nonBusyAirportOutOfCluster.shape[0]):
    code = nonBusyAirportOutOfCluster.iloc[i]['local_code']
    lat = FL_air_loc[FL_air_loc['local_code'] == code]['latitude_deg']
    lon = FL_air_loc[FL_air_loc['local_code'] == code]['longitude_deg']
    coord2 = (lat.values[0],lon.values[0])
    d = geopy.distance.geodesic(coord1, coord2).km
    ref_dist.append(d)
  nonBusyAirportOutOfCluster['ref_dist'] = ref_dist
  nonBusyAirportOutOfCluster = nonBusyAirportOutOfCluster.sort_values(['Delay%','ref_dist','Airport_DelayFlights'])
  
  ref_dist = []
  for i in range(nonBusyAirportInCluster.shape[0]):
    code = nonBusyAirportInCluster.iloc[i]['local_code']
    lat = FL_air_loc[FL_air_loc['local_code'] == code]['latitude_deg']
    lon = FL_air_loc[FL_air_loc['local_code'] == code]['longitude_deg']
    coord2 = (lat.values[0],lon.values[0])
    d = geopy.distance.geodesic(coord1, coord2).km
    ref_dist.append(d)
  nonBusyAirportInCluster['ref_dist'] = ref_dist

  # ref_dist = []
  busyAirportNearby = []
  for i in range(busyAirports.shape[0]):
    code = busyAirports[i,0]
    lat = FL_air_loc[FL_air_loc['local_code'] == code]['latitude_deg']
    lon = FL_air_loc[FL_air_loc['local_code'] == code]['longitude_deg']
    coord2 = (lat.values[0],lon.values[0])
    d = geopy.distance.geodesic(coord1, coord2).km
    midWayCoord = ((coord1[0] + coord2[0])/2, (coord1[1]+coord2[1])/2)
    busyAirportNearby.append([code, d, midWayCoord])
    # ref_dist.append(d)  

  # nonBusyAirportInCluster = nonBusyAirportInCluster.sort_values(['Delay%','Airport_DelayFlights','ref_dist'])
  # print(nonBusyAirportInCluster)
  # print(nonBusyAirportOutOfCluster)
  topChoiceInCluster = []
  nonBusyAirportInCluster = nonBusyAirportInCluster.sort_values(['ref_dist','Delay%','Airport_DelayFlights'])
  # nonBusyAirportInCluster = nonBusyAirportInCluster.sort_values(['ref_dist'])

  # if i_airport == 'MIA':
  #   print('in cluster')
  #   print(nonBusyAirportInCluster)
  for i in range(nonBusyAirportInCluster.shape[0]):
    tmp = nonBusyAirportInCluster.iloc[i]
    # if i_airport == "JAX":
    #   print('in cluster:')
    #   print(topChoiceInCluster['Airport_DelayFlights'])
    if tmp['Airport_DelayFlights'] < i_delayFlights:
        if tmp['ref_dist'] <= 120:
          topChoiceInCluster = tmp
          break

  topChoiceOutCluster = []
  nonBusyAirportOutOfCluster = nonBusyAirportOutOfCluster.sort_values(['ref_dist','Delay%','Airport_DelayFlights'])
  # nonBusyAirportOutOfCluster = nonBusyAirportOutOfCluster.sort_values(['ref_dist'])

  # if i_airport == 'MIA':
  #   print('out cluster')
  #   print(nonBusyAirportOutOfCluster)

  for i in range(nonBusyAirportOutOfCluster.shape[0]):
    tmp = nonBusyAirportOutOfCluster.iloc[i]
    if tmp['Airport_DelayFlights'] < i_delayFlights:
      if tmp['ref_dist'] <= 120:
        topChoiceOutCluster = tmp
        break

  topChoice = []
  if list(topChoiceOutCluster) != [] and list(topChoiceInCluster) != []:
    if topChoiceInCluster['ref_dist'] < topChoiceOutCluster['ref_dist']:
      topChoice.append([topChoiceInCluster])
    else:
      topChoice.append([topChoiceOutCluster])
  elif list(topChoiceInCluster) == [] and list(topChoiceOutCluster) != []:
    topChoice.append([topChoiceOutCluster])
  elif list(topChoiceInCluster) != [] and list(topChoiceOutCluster) == []:
    topChoice.append([topChoiceInCluster])
  else:
    topChoice = []

  if list(topChoice) != []:
    # print(F"Merge with:\n {topChoice}")
    # cluster_list.loc[cluster_list['local_code'] == topChoice[0][0]['local_code'],'cluster'] = i_cluster
    lat = FL_air_loc[FL_air_loc['local_code'] == topChoice[0][0]['local_code']]['latitude_deg']
    lon = FL_air_loc[FL_air_loc['local_code'] == topChoice[0][0]['local_code']]['longitude_deg']
    coord2 = (lat.values[0],lon.values[0])
    midWayCoordToTopChoice = ((coord1[0] + coord2[0])/2, (coord1[1]+coord2[1])/2)
    airspaceOverlappedWithBusy = False
    conflict = []
    for ap in busyAirportNearby:
      if ap[0] == i_airport:
        continue
      else:
        lat = FL_air_loc[FL_air_loc['local_code'] == ap[0]]['latitude_deg']
        lon = FL_air_loc[FL_air_loc['local_code'] == ap[0]]['longitude_deg']
        coord2 = (lat.values[0],lon.values[0])
        d = geopy.distance.geodesic(midWayCoordToTopChoice, coord2).km
        if useCentroidToPreventOverlap == True:
          if d <= topChoice[0][0]['ref_dist']/2:
            airspaceOverlappedWithBusy = True
            conflict = ap
            break
        else:
          if (ap[1] <= topChoice[0][0]['ref_dist']):
            airspaceOverlappedWithBusy = True
            conflict = ap
            break
    if airspaceOverlappedWithBusy == False:
      if generateNewClusterAfterMerging == True:
        maxClusterId += 1
        cluster_list.loc[cluster_list['local_code'] == topChoice[0][0]['local_code'],'cluster'] = maxClusterId
        cluster_list.loc[cluster_list['local_code'] == i_airport,'cluster'] = maxClusterId
        adjustList.append([i_airport,i_cluster,topChoice[0][0]['local_code'],topChoice[0][0]['cluster'],topChoice[0][0]['ref_dist'],maxClusterId])
        print([i_airport,i_cluster,topChoice[0][0]['local_code'],topChoice[0][0]['cluster'],topChoice[0][0]['ref_dist']],maxClusterId)      
      else:
        cluster_list.loc[cluster_list['local_code'] == topChoice[0][0]['local_code'],'cluster'] = i_cluster
        adjustList.append([i_airport,i_cluster,topChoice[0][0]['local_code'],topChoice[0][0]['cluster'],topChoice[0][0]['ref_dist']])
        print([i_airport,i_cluster,topChoice[0][0]['local_code'],topChoice[0][0]['cluster'],topChoice[0][0]['ref_dist']])   
      nonBusyAirportLookupTbl = nonBusyAirportLookupTbl[nonBusyAirportLookupTbl['local_code'] != topChoice[0][0]['local_code']]
      # print(nonBusyAirportLookupTbl)
    else:
      print(F"{i_airport} can not merge with {topChoice[0][0]['local_code']} \n\t airspace conflict with busy airport {conflict}")
      maxClusterId += 1
      cluster_list.loc[cluster_list['local_code'] == i_airport,'cluster'] = maxClusterId
  else:
    maxClusterId += 1
    cluster_list.loc[cluster_list['local_code'] == i_airport,'cluster'] = maxClusterId
    print(F"{i_airport} needs to be further splitted..")

clusterNameLst = np.unique(cluster_list['cluster'].values)

counter = 0
for cName in clusterNameLst:
  cluster_list.loc[cluster_list['cluster'] == cName,'cluster'] = counter
  counter += 1
print(counter)
# print(adjustList)
# print(F"-----------------------------")
print(F"Aft. remerging")
c_delay = cluster_delay(n_mean, cluster_list)
balance_level = statistics.variance(c_delay)
visualize_result_without_recalculate(cluster_list, c_delay)

print(timeStr)
print('Clusters: ', cluster_list['cluster'].values)
print('Delay percentage of each cluster:', c_delay)
print('Unbalnace level of the delay:', balance_level)
print(F"Delay unbalance level b.f. reconfiguration: {statistics.variance(cluster_list['Delay%'].values)}")

arPerSite = cluster_delay(n_mean, cluster_list, True)

print(F"Avg. aircraft handled per airport in cluster: {arPerSite[0]}")
print(F"Avg. delayed aircraft handled per airport in cluster: {arPerSite[1]}")
print(F"Workload unbalance level: {statistics.variance(arPerSite[0])}")
print(F"Workload unbalance level b.f. reconfiguration: {statistics.variance(cluster_list['Airport_Flights'].values)}")
print(F"Delay handling unbalance level: {statistics.variance(arPerSite[1])}")
print(F"Delay handling unbalance level b.f. reconfiguration: {statistics.variance(cluster_list['Airport_DelayFlights'].values)}")
cluster_list

cluster_list[['cluster','local_code']].sort_values(['cluster']).groupby(['cluster'])['local_code'].apply(','.join).reset_index()
# .groupby(['name','month'])['text'].apply(','.join).reset_index()